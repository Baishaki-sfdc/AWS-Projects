{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1a558ee1",
      "metadata": {
        "id": "1a558ee1"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/index_structs/struct_indices/SQLIndexDemo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e45f9b60-cd6b-4c15-958f-1feca5438128",
      "metadata": {
        "id": "e45f9b60-cd6b-4c15-958f-1feca5438128"
      },
      "source": [
        "# Text-to-SQL Guide (Query Engine + Retriever)\n",
        "\n",
        "This is a basic guide to LlamaIndex's Text-to-SQL capabilities.\n",
        "1. We first show how to perform text-to-SQL over a toy dataset: this will do \"retrieval\" (sql query over db) and \"synthesis\".\n",
        "2. We then show how to buid a TableIndex over the schema to dynamically retrieve relevant tables during query-time.\n",
        "3. We finally show you how to define a text-to-SQL retriever on its own.\n",
        "\n",
        "**NOTE:** Any Text-to-SQL application should be aware that executing\n",
        "arbitrary SQL queries can be a security risk. It is recommended to\n",
        "take precautions as needed, such as using restricted roles, read-only\n",
        "databases, sandboxing, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f3f3baa",
      "metadata": {
        "id": "9f3f3baa"
      },
      "source": [
        "If you're opening this Notebook on colab, you will probably need to install LlamaIndex 🦙."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2480c7af",
      "metadata": {
        "id": "2480c7af",
        "outputId": "ab277e0f-d285-4616-f662-157c5b1903c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index-llms-openai\n",
            "  Downloading llama_index_llms_openai-0.3.13-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-index-core<0.13.0,>=0.12.4 (from llama-index-llms-openai)\n",
            "  Downloading llama_index_core-0.12.12-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting openai<2.0.0,>=1.58.1 (from llama-index-llms-openai)\n",
            "  Downloading openai-1.59.9-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (6.0.2)\n",
            "Collecting SQLAlchemy>=1.4.49 (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai)\n",
            "  Downloading SQLAlchemy-2.0.37-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Collecting aiohttp<4.0.0,>=3.8.6 (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai)\n",
            "  Downloading aiohttp-3.11.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting dataclasses-json (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai)\n",
            "  Downloading Deprecated-1.2.15-py2.py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (2024.12.0)\n",
            "Collecting httpx (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai)\n",
            "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (3.4.2)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (2.10.5)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (9.0.0)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai)\n",
            "  Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (4.12.2)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (1.17.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->llama-index-llms-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.58.1->llama-index-llms-openai) (1.7.0)\n",
            "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.58.1->llama-index-llms-openai)\n",
            "  Downloading jiter-0.8.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->llama-index-llms-openai) (1.3.1)\n",
            "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai)\n",
            "  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai)\n",
            "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (24.3.0)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai)\n",
            "  Downloading frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai)\n",
            "  Downloading multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai)\n",
            "  Downloading propcache-0.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai)\n",
            "  Downloading yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.2/69.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->llama-index-llms-openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (2024.12.14)\n",
            "Collecting httpcore==1.* (from httpx->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai)\n",
            "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (2024.11.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (2.3.0)\n",
            "Collecting greenlet!=0.4.17 (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai)\n",
            "  Downloading greenlet-3.1.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai)\n",
            "  Downloading marshmallow-3.25.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (24.2)\n",
            "Downloading llama_index_llms_openai-0.3.13-py3-none-any.whl (14 kB)\n",
            "Downloading llama_index_core-0.12.12-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.59.9-py3-none-any.whl (455 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m455.5/455.5 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp-3.11.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Deprecated-1.2.15-py2.py3-none-any.whl (9.9 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.8.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (345 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.6/345.6 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading SQLAlchemy-2.0.37-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
            "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (274 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.9/274.9 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading greenlet-3.1.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (602 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m602.4/602.4 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.25.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.0/129.0 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading propcache-0.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.1/231.1 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (344 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m344.1/344.1 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, dirtyjson, propcache, mypy-extensions, multidict, marshmallow, jiter, h11, greenlet, frozenlist, deprecated, aiohappyeyeballs, yarl, typing-inspect, tiktoken, SQLAlchemy, httpcore, aiosignal, httpx, dataclasses-json, aiohttp, openai, llama-index-core, llama-index-llms-openai\n",
            "Successfully installed SQLAlchemy-2.0.37 aiohappyeyeballs-2.4.4 aiohttp-3.11.11 aiosignal-1.3.2 dataclasses-json-0.6.7 deprecated-1.2.15 dirtyjson-1.0.8 filetype-1.2.0 frozenlist-1.5.0 greenlet-3.1.1 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 jiter-0.8.2 llama-index-core-0.12.12 llama-index-llms-openai-0.3.13 marshmallow-3.25.1 multidict-6.1.0 mypy-extensions-1.0.0 openai-1.59.9 propcache-0.2.1 tiktoken-0.8.0 typing-inspect-0.9.0 yarl-1.18.3\n"
          ]
        }
      ],
      "source": [
        "%pip install llama-index-llms-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "02b4e312",
      "metadata": {
        "id": "02b4e312",
        "outputId": "e06e245a-fee5-4687-8c3c-b0947cbdc30f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index\n",
            "  Downloading llama_index-0.12.12-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting llama-index-agent-openai<0.5.0,>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_agent_openai-0.4.2-py3-none-any.whl.metadata (727 bytes)\n",
            "Collecting llama-index-cli<0.5.0,>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_cli-0.4.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.12 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.12.12)\n",
            "Collecting llama-index-embeddings-openai<0.4.0,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.6.4-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.13)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.4.2-py3-none-any.whl.metadata (726 bytes)\n",
            "Collecting llama-index-program-openai<0.4.0,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_program_openai-0.3.1-py3-none-any.whl.metadata (764 bytes)\n",
            "Collecting llama-index-question-gen-openai<0.4.0,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl.metadata (783 bytes)\n",
            "Collecting llama-index-readers-file<0.5.0,>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_readers_file-0.4.3-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.59.9)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.12->llama-index) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index) (3.11.11)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index) (1.2.15)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index) (2024.12.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index) (2.10.5)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index) (9.0.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index) (0.8.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index) (1.17.0)\n",
            "Collecting llama-cloud<0.2.0,>=0.1.8 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud-0.1.9-py3-none-any.whl.metadata (911 bytes)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (4.12.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.2.2)\n",
            "Collecting pypdf<6.0.0,>=5.1.0 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index)\n",
            "  Downloading pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.5.19-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.12->llama-index) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.12->llama-index) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.12->llama-index) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.12->llama-index) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.12->llama-index) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.12->llama-index) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.12->llama-index) (1.18.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.6)\n",
            "Requirement already satisfied: certifi<2025.0.0,>=2024.7.4 in /usr/local/lib/python3.11/dist-packages (from llama-cloud<0.2.0,>=0.1.8->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (2024.12.14)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.12->llama-index) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.12->llama-index) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.12->llama-index) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.12->llama-index) (0.14.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.7.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.12->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.12->llama-index) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.12->llama-index) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.12->llama-index) (2.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.12->llama-index) (3.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.12->llama-index) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.12->llama-index) (3.25.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2024.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.12->llama-index) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (1.17.0)\n",
            "Downloading llama_index-0.12.12-py3-none-any.whl (6.9 kB)\n",
            "Downloading llama_index_agent_openai-0.4.2-py3-none-any.whl (13 kB)\n",
            "Downloading llama_index_cli-0.4.0-py3-none-any.whl (27 kB)\n",
            "Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
            "Downloading llama_index_indices_managed_llama_cloud-0.6.4-py3-none-any.whl (13 kB)\n",
            "Downloading llama_index_multi_modal_llms_openai-0.4.2-py3-none-any.whl (5.9 kB)\n",
            "Downloading llama_index_program_openai-0.3.1-py3-none-any.whl (5.3 kB)\n",
            "Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl (2.9 kB)\n",
            "Downloading llama_index_readers_file-0.4.3-py3-none-any.whl (38 kB)\n",
            "Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
            "Downloading llama_cloud-0.1.9-py3-none-any.whl (240 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.0/241.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_parse-0.5.19-py3-none-any.whl (15 kB)\n",
            "Downloading pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Installing collected packages: striprtf, pypdf, llama-cloud, llama-parse, llama-index-readers-file, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
            "Successfully installed llama-cloud-0.1.9 llama-index-0.12.12 llama-index-agent-openai-0.4.2 llama-index-cli-0.4.0 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.6.4 llama-index-multi-modal-llms-openai-0.4.2 llama-index-program-openai-0.3.1 llama-index-question-gen-openai-0.3.0 llama-index-readers-file-0.4.3 llama-index-readers-llama-parse-0.4.0 llama-parse-0.5.19 pypdf-5.1.0 striprtf-0.0.26\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f69be8d-99ae-4d9f-91e4-b90fc62bcf2e",
      "metadata": {
        "id": "0f69be8d-99ae-4d9f-91e4-b90fc62bcf2e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e28ca96e-f98f-4a72-9fe3-a372dbd08a8b",
      "metadata": {
        "id": "e28ca96e-f98f-4a72-9fe3-a372dbd08a8b"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-..\"\n",
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "119eb42b",
      "metadata": {
        "id": "119eb42b"
      },
      "outputs": [],
      "source": [
        "# import logging\n",
        "# import sys\n",
        "\n",
        "# logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "# logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "107396a9-4aa7-49b3-9f0f-a755726c19ba",
      "metadata": {
        "id": "107396a9-4aa7-49b3-9f0f-a755726c19ba"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Markdown, display"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "461438c8-302d-45c5-8e69-16ad604686d1",
      "metadata": {
        "id": "461438c8-302d-45c5-8e69-16ad604686d1"
      },
      "source": [
        "### Create Database Schema\n",
        "\n",
        "We use `sqlalchemy`, a popular SQL database toolkit, to create an empty `city_stats` Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a370b266-66f5-4624-bbf9-2ad57f0511f8",
      "metadata": {
        "id": "a370b266-66f5-4624-bbf9-2ad57f0511f8"
      },
      "outputs": [],
      "source": [
        "from sqlalchemy import (\n",
        "    create_engine,\n",
        "    MetaData,\n",
        "    Table,\n",
        "    Column,\n",
        "    String,\n",
        "    Integer,\n",
        "    select,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea24f794-f10b-42e6-922d-9258b7167405",
      "metadata": {
        "id": "ea24f794-f10b-42e6-922d-9258b7167405"
      },
      "outputs": [],
      "source": [
        "engine = create_engine(\"sqlite:///:memory:\")\n",
        "metadata_obj = MetaData()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4154b29-7e23-4c26-a507-370a66186ae7",
      "metadata": {
        "id": "b4154b29-7e23-4c26-a507-370a66186ae7"
      },
      "outputs": [],
      "source": [
        "# create city SQL table\n",
        "table_name = \"city_stats\"\n",
        "city_stats_table = Table(\n",
        "    table_name,\n",
        "    metadata_obj,\n",
        "    Column(\"city_name\", String(16), primary_key=True),\n",
        "    Column(\"population\", Integer),\n",
        "    Column(\"country\", String(16), nullable=False),\n",
        ")\n",
        "metadata_obj.create_all(engine)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c09089a-6bcd-48db-8120-a84c8da3f82e",
      "metadata": {
        "id": "1c09089a-6bcd-48db-8120-a84c8da3f82e"
      },
      "source": [
        "### Define SQL Database\n",
        "\n",
        "We first define our `SQLDatabase` abstraction (a light wrapper around SQLAlchemy)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "768d1581-b482-4c73-9963-5ffd68a2aafb",
      "metadata": {
        "id": "768d1581-b482-4c73-9963-5ffd68a2aafb"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import SQLDatabase\n",
        "from llama_index.llms.openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bffabba0-8e54-4f24-ad14-2c8979c582a5",
      "metadata": {
        "id": "bffabba0-8e54-4f24-ad14-2c8979c582a5"
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(temperature=0.1, model=\"gpt-3.5-turbo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9432787b-a8f0-4fc3-8323-e2cd9497df73",
      "metadata": {
        "id": "9432787b-a8f0-4fc3-8323-e2cd9497df73"
      },
      "outputs": [],
      "source": [
        "sql_database = SQLDatabase(engine, include_tables=[\"city_stats\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bad7ffbe",
      "metadata": {
        "id": "bad7ffbe"
      },
      "source": [
        "We add some testing data to our SQL database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95043e10-6cdf-4f66-96bd-ce307ea7df3e",
      "metadata": {
        "id": "95043e10-6cdf-4f66-96bd-ce307ea7df3e"
      },
      "outputs": [],
      "source": [
        "sql_database = SQLDatabase(engine, include_tables=[\"city_stats\"])\n",
        "from sqlalchemy import insert\n",
        "\n",
        "rows = [\n",
        "    {\"city_name\": \"Toronto\", \"population\": 2930000, \"country\": \"Canada\"},\n",
        "    {\"city_name\": \"Tokyo\", \"population\": 13960000, \"country\": \"Japan\"},\n",
        "    {\n",
        "        \"city_name\": \"Chicago\",\n",
        "        \"population\": 2679000,\n",
        "        \"country\": \"United States\",\n",
        "    },\n",
        "    {\"city_name\": \"Seoul\", \"population\": 9776000, \"country\": \"South Korea\"},\n",
        "]\n",
        "for row in rows:\n",
        "    stmt = insert(city_stats_table).values(**row)\n",
        "    with engine.begin() as connection:\n",
        "        cursor = connection.execute(stmt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b315b8ff-7dd7-4e7d-ac47-8c5a0c3e7ae9",
      "metadata": {
        "id": "b315b8ff-7dd7-4e7d-ac47-8c5a0c3e7ae9",
        "outputId": "00aa1b28-2ffe-45dd-be40-a439cfc109aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('Toronto', 2930000, 'Canada'), ('Tokyo', 13960000, 'Japan'), ('Chicago', 2679000, 'United States'), ('Seoul', 9776000, 'South Korea')]\n"
          ]
        }
      ],
      "source": [
        "# view current table\n",
        "stmt = select(\n",
        "    city_stats_table.c.city_name,\n",
        "    city_stats_table.c.population,\n",
        "    city_stats_table.c.country,\n",
        ").select_from(city_stats_table)\n",
        "\n",
        "with engine.connect() as connection:\n",
        "    results = connection.execute(stmt).fetchall()\n",
        "    print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "051a171f-8c97-40ed-ae17-4e3fa3785487",
      "metadata": {
        "id": "051a171f-8c97-40ed-ae17-4e3fa3785487"
      },
      "source": [
        "### Query Index"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6a2303f-3bae-4fa2-8750-03f9af747848",
      "metadata": {
        "id": "f6a2303f-3bae-4fa2-8750-03f9af747848"
      },
      "source": [
        "We first show how we can execute a raw SQL query, which directly executes over the table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eddd3608-31ff-4591-a02a-90987e312669",
      "metadata": {
        "id": "eddd3608-31ff-4591-a02a-90987e312669",
        "outputId": "9802471f-cddb-4d51-a8eb-fe954a28cb67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('Chicago',)\n",
            "('Seoul',)\n",
            "('Tokyo',)\n",
            "('Toronto',)\n"
          ]
        }
      ],
      "source": [
        "from sqlalchemy import text\n",
        "\n",
        "with engine.connect() as con:\n",
        "    rows = con.execute(text(\"SELECT city_name from city_stats\"))\n",
        "    for row in rows:\n",
        "        print(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e72b931",
      "metadata": {
        "id": "4e72b931"
      },
      "source": [
        "## Part 1: Text-to-SQL Query Engine\n",
        "Once we have constructed our SQL database, we can use the NLSQLTableQueryEngine to\n",
        "construct natural language queries that are synthesized into SQL queries.\n",
        "\n",
        "Note that we need to specify the tables we want to use with this query engine.\n",
        "If we don't the query engine will pull all the schema context, which could\n",
        "overflow the context window of the LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d992fb5",
      "metadata": {
        "id": "5d992fb5"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.query_engine import NLSQLTableQueryEngine\n",
        "\n",
        "query_engine = NLSQLTableQueryEngine(\n",
        "    sql_database=sql_database, tables=[\"city_stats\"], llm=llm\n",
        ")\n",
        "query_str = \"Which city has the highest population?\"\n",
        "response = query_engine.query(query_str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c0dfe9c",
      "metadata": {
        "id": "7c0dfe9c",
        "outputId": "10e58355-3e84-4aab-b69d-5813354a89fe"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "<b>The city with the highest population is Tokyo.</b>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(Markdown(f\"<b>{response}</b>\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "298b4ca2",
      "metadata": {
        "id": "298b4ca2"
      },
      "source": [
        "This query engine should be used in any case where you can specify the tables you want\n",
        "to query over beforehand, or the total size of all the table schema plus the rest of\n",
        "the prompt fits your context window."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dee4d251",
      "metadata": {
        "id": "dee4d251"
      },
      "source": [
        "## Part 2: Query-Time Retrieval of Tables for Text-to-SQL\n",
        "If we don't know ahead of time which table we would like to use, and the total size of\n",
        "the table schema overflows your context window size, we should store the table schema\n",
        "in an index so that during query time we can retrieve the right schema.\n",
        "\n",
        "The way we can do this is using the SQLTableNodeMapping object, which takes in a\n",
        "SQLDatabase and produces a Node object for each SQLTableSchema object passed\n",
        "into the ObjectIndex constructor.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d71045c0-7a96-4e86-b38c-c378b7759aa4",
      "metadata": {
        "id": "d71045c0-7a96-4e86-b38c-c378b7759aa4"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.indices.struct_store.sql_query import (\n",
        "    SQLTableRetrieverQueryEngine,\n",
        ")\n",
        "from llama_index.core.objects import (\n",
        "    SQLTableNodeMapping,\n",
        "    ObjectIndex,\n",
        "    SQLTableSchema,\n",
        ")\n",
        "from llama_index.core import VectorStoreIndex\n",
        "\n",
        "# set Logging to DEBUG for more detailed outputs\n",
        "table_node_mapping = SQLTableNodeMapping(sql_database)\n",
        "table_schema_objs = [\n",
        "    (SQLTableSchema(table_name=\"city_stats\"))\n",
        "]  # add a SQLTableSchema for each table\n",
        "\n",
        "obj_index = ObjectIndex.from_objects(\n",
        "    table_schema_objs,\n",
        "    table_node_mapping,\n",
        "    VectorStoreIndex,\n",
        ")\n",
        "query_engine = SQLTableRetrieverQueryEngine(\n",
        "    sql_database, obj_index.as_retriever(similarity_top_k=1)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6156caf",
      "metadata": {
        "id": "b6156caf"
      },
      "source": [
        "Now we can take our SQLTableRetrieverQueryEngine and query it for our response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "802da9ed",
      "metadata": {
        "id": "802da9ed",
        "outputId": "25e7fe76-7db2-47d4-d407-d5b9829dc505"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "<b>The city with the highest population is Tokyo.</b>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "response = query_engine.query(\"Which city has the highest population?\")\n",
        "display(Markdown(f\"<b>{response}</b>\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54a99cb0-578a-40ec-a3eb-1666ac18fbed",
      "metadata": {
        "id": "54a99cb0-578a-40ec-a3eb-1666ac18fbed",
        "outputId": "be92f8b4-f434-4230-fb4c-45f1bf95e400"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('Tokyo',)]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# you can also fetch the raw result from SQLAlchemy!\n",
        "response.metadata[\"result\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d19b9cd",
      "metadata": {
        "id": "0d19b9cd"
      },
      "source": [
        "You can also add additional context information for each table schema you define."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44a87651",
      "metadata": {
        "id": "44a87651"
      },
      "outputs": [],
      "source": [
        "# manually set context text\n",
        "city_stats_text = (\n",
        "    \"This table gives information regarding the population and country of a\"\n",
        "    \" given city.\\nThe user will query with codewords, where 'foo' corresponds\"\n",
        "    \" to population and 'bar'corresponds to city.\"\n",
        ")\n",
        "\n",
        "table_node_mapping = SQLTableNodeMapping(sql_database)\n",
        "table_schema_objs = [\n",
        "    (SQLTableSchema(table_name=\"city_stats\", context_str=city_stats_text))\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ef57746-7cbf-48cd-8781-9c048ce3d3c7",
      "metadata": {
        "id": "2ef57746-7cbf-48cd-8781-9c048ce3d3c7"
      },
      "source": [
        "## Part 3: Text-to-SQL Retriever\n",
        "\n",
        "So far our text-to-SQL capability is packaged in a query engine and consists of both retrieval and synthesis.\n",
        "\n",
        "You can use the SQL retriever on its own. We show you some different parameters you can try, and also show how to plug it into our `RetrieverQueryEngine` to get roughly the same results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99128819-6acf-4717-b703-9d1ca41190a5",
      "metadata": {
        "id": "99128819-6acf-4717-b703-9d1ca41190a5"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.retrievers import NLSQLRetriever\n",
        "\n",
        "# default retrieval (return_raw=True)\n",
        "nl_sql_retriever = NLSQLRetriever(\n",
        "    sql_database, tables=[\"city_stats\"], return_raw=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19bc6858-7e3b-4cf1-806f-0d6d63a55d61",
      "metadata": {
        "id": "19bc6858-7e3b-4cf1-806f-0d6d63a55d61"
      },
      "outputs": [],
      "source": [
        "results = nl_sql_retriever.retrieve(\n",
        "    \"Return the top 5 cities (along with their populations) with the highest population.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3576523f-0b5c-4c40-8b2a-d734bdfbde58",
      "metadata": {
        "id": "3576523f-0b5c-4c40-8b2a-d734bdfbde58",
        "outputId": "9f4a4351-2623-4365-bedc-14143461b462"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "**Node ID:** 458f723e-f1ac-4423-917a-522a71763390<br>**Similarity:** None<br>**Text:** [('Tokyo', 13960000), ('Seoul', 9776000), ('Toronto', 2930000), ('Chicago', 2679000)]<br>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from llama_index.core.response.notebook_utils import display_source_node\n",
        "\n",
        "for n in results:\n",
        "    display_source_node(n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acfdc307-65e1-4a0e-8098-f30c0db60c93",
      "metadata": {
        "id": "acfdc307-65e1-4a0e-8098-f30c0db60c93"
      },
      "outputs": [],
      "source": [
        "# default retrieval (return_raw=False)\n",
        "nl_sql_retriever = NLSQLRetriever(\n",
        "    sql_database, tables=[\"city_stats\"], return_raw=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36ccfa42-51e0-49e7-afac-6a0d011af4e2",
      "metadata": {
        "id": "36ccfa42-51e0-49e7-afac-6a0d011af4e2"
      },
      "outputs": [],
      "source": [
        "results = nl_sql_retriever.retrieve(\n",
        "    \"Return the top 5 cities (along with their populations) with the highest population.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cd14d5e-7a5c-4898-820a-469b80cee5c9",
      "metadata": {
        "id": "5cd14d5e-7a5c-4898-820a-469b80cee5c9",
        "outputId": "eba10522-63af-4380-f01a-0a6d557a6fa7"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "**Node ID:** 7c0e4c94-c9a6-4917-aa3f-e3b3f4cbcd5c<br>**Similarity:** None<br>**Text:** <br>**Metadata:** {'city_name': 'Tokyo', 'population': 13960000}<br>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "**Node ID:** 3c1d1caa-cec2-451e-8fd1-adc944e1d050<br>**Similarity:** None<br>**Text:** <br>**Metadata:** {'city_name': 'Seoul', 'population': 9776000}<br>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "**Node ID:** fb9f9b25-b913-4dde-a0e3-6111f704aea9<br>**Similarity:** None<br>**Text:** <br>**Metadata:** {'city_name': 'Toronto', 'population': 2930000}<br>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "**Node ID:** c31ba8e7-de5d-4f28-a464-5e0339547c70<br>**Similarity:** None<br>**Text:** <br>**Metadata:** {'city_name': 'Chicago', 'population': 2679000}<br>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# NOTE: all the content is in the metadata\n",
        "for n in results:\n",
        "    display_source_node(n, show_source_metadata=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "392889f6-babe-4bce-b802-4379a9b3ca49",
      "metadata": {
        "id": "392889f6-babe-4bce-b802-4379a9b3ca49"
      },
      "source": [
        "### Plug into our `RetrieverQueryEngine`\n",
        "\n",
        "We compose our SQL Retriever with our standard `RetrieverQueryEngine` to synthesize a response. The result is roughly similar to our packaged `Text-to-SQL` query engines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f85e7a24-bbd0-4439-9da4-26a7a9e43b8a",
      "metadata": {
        "id": "f85e7a24-bbd0-4439-9da4-26a7a9e43b8a"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "\n",
        "query_engine = RetrieverQueryEngine.from_args(nl_sql_retriever)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50f2dec0-8700-49d3-81b7-69c21518ac87",
      "metadata": {
        "id": "50f2dec0-8700-49d3-81b7-69c21518ac87"
      },
      "outputs": [],
      "source": [
        "response = query_engine.query(\n",
        "    \"Return the top 5 cities (along with their populations) with the highest population.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56eb7e5a-a23b-47ab-a154-98ce4c0d1c1c",
      "metadata": {
        "id": "56eb7e5a-a23b-47ab-a154-98ce4c0d1c1c",
        "outputId": "d1bc925e-113c-49a3-f3b7-fdd6668cabd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The top 5 cities with the highest population are:\n",
            "\n",
            "1. Tokyo - 13,960,000\n",
            "2. Seoul - 9,776,000\n",
            "3. Toronto - 2,930,000\n",
            "4. Chicago - 2,679,000\n"
          ]
        }
      ],
      "source": [
        "print(str(response))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "llama_index_v2",
      "language": "python",
      "name": "llama_index_v2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}